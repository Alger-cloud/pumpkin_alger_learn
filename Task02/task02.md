## 第三章 线性模型

&emsp;&emsp;线性模型形式简单、易于建模，但却蕴涵着机器学习中一些重要的基本思
想.许多功能更为强大的非线性模型(nonlinear model) 可在线性模型的基础上
通过引入层级结构或高维映射而得.此外，由于 直观表达了各属性在预测中
的重要性，因此线性模型有很好的可解释'性 (comprehensibility) .

### 3.2 线性回归
&emsp;&emsp;"线性回归" (linear regression) 试图学得一个线性模型以尽可能准确地预测实值输出标记.
&emsp;&emsp;基于均方误差最小化来进行模型求解的方法称为"最小二乘法" (least squ method). 
$$y = g^{-1}(w^T*x+b)$$
### 3.3 对数几率回归
&emsp;&emsp; **Question:** 对于用线性模型进行二分类的任务：输出标记 νε{0，1} 

&emsp;&emsp; **>>>Answer:** 将z转换为0,1值. 最理想的是"单位跃函数" (unit-step function) 

&emsp;&emsp; **Question:** 单位阶跃函数不连续，因此不能直接用作式(3.15)g-(-). 于是我们希望找到能在一定程度上近似单位阶跃函数的"替代函数" (surrogate function) ，并希望它单调可微.

&emsp;&emsp; **>>>Answer:** 对数几率函数(logisticfunction) 正是这样一个常用的替代函数。对数几率函数是一种 "Sigmoid 函数"
### 3.4 线性判别分析
&emsp;&emsp; **线性判别分析(Linear Discriminant analys)** :简称 LDA 经典的线，在二分类问题上因为最早由Fishe 1936提出,亦称 "Fisher 
&emsp;&emsp; LDA的思想非常简单: 给定训练样法将样例投影到一条使得同样例的投影点尽可能接近、 异类样例投影点能远离;在对新样本进行分类时，将其投影到 同样的这条直线上，再根据投 点的位置来确定样本的类别.
&emsp;&emsp; 若将W视为一个投影矩阵，则多分类 LDA 将样本投影到 N-1 维空间，N-1 通常远小子数据原有的属性数.于是，可通过这个投影来减小样本点的维数，且投影过程中使用了类别信息?因此LDA也常被视为一种经典的监督降维技术。

**参考文献：周志华《机器学习》**